{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import (\n",
        "    mean_absolute_error,\n",
        "    root_mean_squared_error,\n",
        "    mean_absolute_percentage_error,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simulazione degli argomenti per il notebook\n",
        "class Args:\n",
        "    def __init__(self):\n",
        "        self.output_path = \"outputs/val_set\"\n",
        "        self.scores_path = \"scores/val_set\"\n",
        "\n",
        "\n",
        "args = Args()\n",
        "\n",
        "HYPO = 70.0\n",
        "HYPER = 180.0\n",
        "\n",
        "print(f\"Configurazione:\")\n",
        "print(f\"  - Output path: {args.output_path}\")\n",
        "print(f\"  - Scores path: {args.scores_path}\")\n",
        "print(f\"  - Hypo threshold: {HYPO}\")\n",
        "print(f\"  - Hyper threshold: {HYPER}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "file_prefixes = [file for file in os.listdir(args.output_path) if \"output\" in file]\n",
        "\n",
        "os.makedirs(args.scores_path, exist_ok=True)\n",
        "cumulative_results = []\n",
        "condition_results = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for file in os.listdir(args.output_path):\n",
        "    if \"output\" not in file:\n",
        "        continue\n",
        "\n",
        "    test_set = pd.read_csv(f\"{args.output_path}/{file}\")\n",
        "    test_set[\"bgClass\"] = test_set[\"target\"].apply(\n",
        "        lambda x: \"Hypo\" if x < HYPO else (\"Hyper\" if x > HYPER else \"Normal\")\n",
        "    )\n",
        "\n",
        "    maes, mapes, rmses = [], [], []\n",
        "    for subject in test_set[\"Patient_ID\"].unique():\n",
        "        x = test_set[test_set[\"Patient_ID\"] == subject]\n",
        "        maes.append(mean_absolute_error(x[\"target\"], x[\"y_pred\"]))\n",
        "        mapes.append(mean_absolute_percentage_error(x[\"target\"], x[\"y_pred\"]) * 100)\n",
        "        rmses.append(root_mean_squared_error(x[\"target\"], x[\"y_pred\"]))\n",
        "\n",
        "    cumulative_results.append(\n",
        "        [\n",
        "            file[:-11].upper(),\n",
        "            f\"{np.mean(maes):.2f}({np.std(maes):.2f})\",\n",
        "            f\"{np.mean(mapes):.2f}({np.std(mapes):.2f})\",\n",
        "            f\"{np.mean(rmses):.2f}({np.std(rmses):.2f})\",\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    for condition in [\"Normal\", \"Hyper\", \"Hypo\"]:\n",
        "        dummy = test_set[test_set[\"bgClass\"] == condition]\n",
        "        maes, mapes, rmses = [], [], []\n",
        "        for subject in test_set[\"Patient_ID\"].unique():\n",
        "            x = dummy[dummy[\"Patient_ID\"] == subject]\n",
        "            if x.empty:\n",
        "                continue\n",
        "            maes.append(mean_absolute_error(x[\"target\"], x[\"y_pred\"]))\n",
        "            mapes.append(mean_absolute_percentage_error(x[\"target\"], x[\"y_pred\"]) * 100)\n",
        "            rmses.append(root_mean_squared_error(x[\"target\"], x[\"y_pred\"]))\n",
        "\n",
        "        condition_results.append(\n",
        "            [\n",
        "                file[:-11].upper(),\n",
        "                condition,\n",
        "                f\"{np.mean(maes):.2f}({np.std(maes):.2f})\",\n",
        "                f\"{np.mean(mapes):.2f}({np.std(mapes):.2f})\",\n",
        "                f\"{np.mean(rmses):.2f}({np.std(rmses):.2f})\",\n",
        "            ]\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cumulative_df = pd.DataFrame(\n",
        "    cumulative_results, columns=[\"Model\", \"MAE\", \"MAPE\", \"RMSE\"]\n",
        ")\n",
        "cumulative_df.to_csv(f\"{args.scores_path}/cumulative_results.csv\", index=False)\n",
        "\n",
        "print(\"Cumulative Results:\")\n",
        "print(cumulative_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "condition_df = pd.DataFrame(\n",
        "    condition_results, columns=[\"Model\", \"Condition\", \"MAE\", \"MAPE\", \"RMSE\"]\n",
        ")\n",
        "condition_pivot = condition_df.pivot(\n",
        "    index=\"Model\", columns=\"Condition\", values=[\"MAE\", \"MAPE\", \"RMSE\"]\n",
        ")\n",
        "condition_pivot.columns = [\n",
        "    f\"{metric} ({condition})\" for metric, condition in condition_pivot.columns\n",
        "]\n",
        "condition_pivot.reset_index(inplace=True)\n",
        "condition_pivot.to_csv(f\"{args.scores_path}/condition_results.csv\", index=False)\n",
        "\n",
        "print(\"\\nCondition Results:\")\n",
        "print(condition_pivot)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
