{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Deep Neural Networks Training\n",
    "\n",
    "This notebook trains MLP, LSTM, and GRU models using PyTorch for glucose prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from torch import optim, nn\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Add paths for imports\n",
    "sys.path.append(\"training\")\n",
    "\n",
    "# Import existing functions\n",
    "from split_data import load_splits, rescale_data, print_results\n",
    "from pt_utils_dnn import (\n",
    "    MLPModel,\n",
    "    RNNModel,\n",
    "    EarlyStopper,\n",
    "    get_dataloader,\n",
    "    train_model,\n",
    "    predict_in_batches,\n",
    "    get_params_count\n",
    ")\n",
    "\n",
    "print(\"Libraries imported successfully\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "config = {\n",
    "    \"output_dir\": \"outputs\",\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"seed\": 42,\n",
    "    \"batch_size\": 4096,\n",
    "    \"dropout\": 0.2,\n",
    "    \"activation\": \"tanh\",\n",
    "    \"epochs\": 100,\n",
    "    \"lr\": 0.01,\n",
    "    \"min_lr\": 1e-6,\n",
    "    \"lr_patience\": 3,\n",
    "    \"patience\": 5,\n",
    "    \"num_layers\": 2,\n",
    "    \"models\": {\n",
    "        \"mlp\": {\"hidden_size\": 256},\n",
    "        \"lstm\": {\"hidden_size\": 75},\n",
    "        \"gru\": {\"hidden_size\": 86}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(config[\"output_dir\"], exist_ok=True)\n",
    "\n",
    "# Set random seed\n",
    "torch.manual_seed(config[\"seed\"])\n",
    "\n",
    "print(\"Configuration:\")\n",
    "for key, value in config.items():\n",
    "    if key != \"models\":\n",
    "        print(f\"  {key}: {value}\")\n",
    "print(\"\\nModel configurations:\")\n",
    "for model_name, model_config in config[\"models\"].items():\n",
    "    print(f\"  {model_name}: {model_config}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading pre-prepared data splits...\")\n",
    "train_set, val_set, test_set, X_cols, y_cols = load_splits()\n",
    "\n",
    "print(f\"Data loaded successfully:\")\n",
    "print(f\"  Train set: {train_set.shape}\")\n",
    "print(f\"  Validation set: {val_set.shape}\")\n",
    "print(f\"  Test set: {test_set.shape}\")\n",
    "print(f\"  Features: {len(X_cols)}\")\n",
    "print(f\"  Target: {y_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pytorch_model(model_name, model_config, X_cols):\n",
    "    \"\"\"Create PyTorch model based on configuration\"\"\"\n",
    "    hidden_size = model_config[\"hidden_size\"]\n",
    "    \n",
    "    if model_name == \"mlp\":\n",
    "        input_size = len(X_cols)\n",
    "        model = MLPModel(\n",
    "            input_size=input_size,\n",
    "            hidden_sizes=[hidden_size] * config[\"num_layers\"],\n",
    "            dropout=config[\"dropout\"],\n",
    "            activation=config[\"activation\"]\n",
    "        )\n",
    "    else:  # lstm or gru\n",
    "        input_size = 1  # For RNN models\n",
    "        model = RNNModel(\n",
    "            variant=model_name,\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=config[\"num_layers\"],\n",
    "            dropout=config[\"dropout\"]\n",
    "        )\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def train_pytorch_model(model_name, model_config):\n",
    "    \"\"\"Train a PyTorch model and return results\"\"\"\n",
    "    print(f\"\\nCreating {model_name.upper()} model...\")\n",
    "    model = create_pytorch_model(model_name, model_config, X_cols)\n",
    "    \n",
    "    print(f\"\\nModel architecture for {model_name.upper()}:\")\n",
    "    get_params_count(model)\n",
    "    \n",
    "    # Prepare data loaders\n",
    "    print(f\"\\nPreparing data loaders for {model_name.upper()}...\")\n",
    "    train_loader, val_loader = get_dataloader(\n",
    "        train_set, val_set, X_cols, y_cols, model_name, config[\"batch_size\"]\n",
    "    )\n",
    "    \n",
    "    # Setup training components\n",
    "    criterion = nn.HuberLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config[\"lr\"])\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, patience=config[\"lr_patience\"], min_lr=config[\"min_lr\"]\n",
    "    )\n",
    "    early_stopper = EarlyStopper(patience=config[\"patience\"])\n",
    "    \n",
    "    # Train model\n",
    "    print(f\"\\nTraining {model_name.upper()} model...\")\n",
    "    model = train_model(\n",
    "        model=model,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        early_stopper=early_stopper,\n",
    "        train_loader=train_loader,\n",
    "        test_loader=val_loader,\n",
    "        device=config[\"device\"],\n",
    "        epochs=config[\"epochs\"],\n",
    "        output_path=config[\"output_dir\"],\n",
    "        exp_name=model_name\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_pytorch_model(model, model_name):\n",
    "    \"\"\"Evaluate model and save results\"\"\"\n",
    "    print(f\"\\nEvaluating {model_name.upper()} model on validation set...\")\n",
    "    \n",
    "    # Make predictions\n",
    "    val_set_eval = val_set.copy()\n",
    "    val_set_eval[\"y_pred\"] = predict_in_batches(\n",
    "        model, val_set_eval[X_cols], config[\"device\"], model_name\n",
    "    )\n",
    "    \n",
    "    # Prepare results\n",
    "    val_set_eval = val_set_eval.rename(columns={y_cols[-1]: \"target\"})\n",
    "    val_set_eval = rescale_data(val_set_eval, [\"target\", \"y_pred\"])\n",
    "    \n",
    "    # Select output columns\n",
    "    output_columns = [\"Timestamp\", \"Patient_ID\", \"bgClass\", \"target\", \"y_pred\"]\n",
    "    results = val_set_eval[output_columns]\n",
    "    \n",
    "    # Print evaluation results\n",
    "    print(f\"\\nEvaluation results for {model_name.upper()}:\")\n",
    "    print_results(results)\n",
    "    \n",
    "    # Save results\n",
    "    output_file = f\"{config['output_dir']}/{model_name}_output.csv\"\n",
    "    results.to_csv(output_file, index=False)\n",
    "    print(f\"Results saved to: {output_file}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"Training functions defined successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate each model\n",
    "results_summary = {}\n",
    "trained_models = {}\n",
    "\n",
    "for model_name, model_config in config[\"models\"].items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"TRAINING AND EVALUATION - {model_name.upper()}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Train model\n",
    "    model = train_pytorch_model(model_name, model_config)\n",
    "    trained_models[model_name] = model\n",
    "    \n",
    "    # Evaluate model\n",
    "    results = evaluate_pytorch_model(model, model_name)\n",
    "    \n",
    "    # Store results for summary\n",
    "    mae = results.apply(lambda row: abs(row['target'] - row['y_pred']), axis=1).mean()\n",
    "    rmse = ((results['target'] - results['y_pred']) ** 2).mean() ** 0.5\n",
    "    \n",
    "    results_summary[model_name] = {\n",
    "        'Model': model_name.upper(),\n",
    "        'Hidden Size': model_config['hidden_size'],\n",
    "        'MAE': round(mae, 4),\n",
    "        'RMSE': round(rmse, 4),\n",
    "        'Parameters': sum(p.numel() for p in model.parameters())\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{model_name.upper()} training completed!\")\n",
    "    print(f\"  MAE: {mae:.4f}\")\n",
    "    print(f\"  RMSE: {rmse:.4f}\")\n",
    "    print(f\"  Model saved: {config['output_dir']}/{model_name}.pt\")\n",
    "    print(f\"  Results saved: {config['output_dir']}/{model_name}_output.csv\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ALL MODELS TRAINING COMPLETED\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary DataFrame\n",
    "summary_data = []\n",
    "for model_name, metrics in results_summary.items():\n",
    "    summary_data.append(metrics)\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"PYTORCH MODELS SUMMARY TABLE:\")\n",
    "print(f\"{'='*80}\")\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "# Save summary\n",
    "summary_path = f\"{config['output_dir']}/pytorch_models_summary.csv\"\n",
    "summary_df.to_csv(summary_path, index=False)\n",
    "print(f\"\\nSummary saved to: {summary_path}\")\n",
    "\n",
    "# Find best model\n",
    "best_model = summary_df.loc[summary_df['MAE'].idxmin()]\n",
    "print(f\"\\nBest performing model: {best_model['Model']} (MAE: {best_model['MAE']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Create comparison plots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# MAE comparison\n",
    "axes[0].bar(summary_df['Model'], summary_df['MAE'], color=['#1f77b4', '#ff7f0e', '#2ca02c'])\n",
    "axes[0].set_title('Model Performance - MAE Comparison')\n",
    "axes[0].set_ylabel('MAE')\n",
    "axes[0].set_xlabel('Model')\n",
    "for i, v in enumerate(summary_df['MAE']):\n",
    "    axes[0].text(i, v + 0.01, f'{v:.4f}', ha='center', va='bottom')\n",
    "\n",
    "# Parameters comparison\n",
    "axes[1].bar(summary_df['Model'], summary_df['Parameters'], color=['#1f77b4', '#ff7f0e', '#2ca02c'])\n",
    "axes[1].set_title('Model Complexity - Parameters Comparison')\n",
    "axes[1].set_ylabel('Number of Parameters')\n",
    "axes[1].set_xlabel('Model')\n",
    "for i, v in enumerate(summary_df['Parameters']):\n",
    "    axes[1].text(i, v + max(summary_df['Parameters'])*0.01, f'{v:,}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{config['output_dir']}/pytorch_models_comparison.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nComparison plot saved to: {config['output_dir']}/pytorch_models_comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PYTORCH TRAINING PIPELINE COMPLETED SUCCESSFULLY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nAll models trained and evaluated:\")\n",
    "for model_name in config[\"models\"].keys():\n",
    "    print(f\"  âœ“ {model_name.upper()}\")\n",
    "\n",
    "print(f\"\\nFiles generated:\")\n",
    "for model_name in config[\"models\"].keys():\n",
    "    print(f\"  - {config['output_dir']}/{model_name}.pt (model weights)\")\n",
    "    print(f\"  - {config['output_dir']}/{model_name}_output.csv (predictions)\")\n",
    "print(f\"  - {config['output_dir']}/pytorch_models_summary.csv (summary)\")\n",
    "print(f\"  - {config['output_dir']}/pytorch_models_comparison.png (comparison plot)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}