{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from final_training.gen_vs_pers import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simulazione degli argomenti per il notebook\n",
        "class Args:\n",
        "    def __init__(self):\n",
        "        self.gru_results_file = \"outputs/test_set/gru_output.csv\"\n",
        "        self.xgb_results_file = \"outputs/test_set/xgb_output.csv\"\n",
        "        self.output_dir = \"outputs/personalized\"\n",
        "        self.models_dir = \"models/personalized\"\n",
        "        self.scores_dir = \"scores/gen_vs_pers\"\n",
        "        self.plots_dir = \"plots/gen_vs_pers\"\n",
        "        self.test_split = 0.2\n",
        "        self.seed = 42\n",
        "        self.epochs = 100\n",
        "        self.batch_size = 256\n",
        "        self.lr = 0.01\n",
        "        self.es_patience = 20\n",
        "\n",
        "\n",
        "args = Args()\n",
        "\n",
        "# Verifica i parametri\n",
        "print(f\"Configurazione:\")\n",
        "print(f\"  - GRU results file: {args.gru_results_file}\")\n",
        "print(f\"  - XGB results file: {args.xgb_results_file}\")\n",
        "print(f\"  - Output dir: {args.output_dir}\")\n",
        "print(f\"  - Models dir: {args.models_dir}\")\n",
        "print(f\"  - Scores dir: {args.scores_dir}\")\n",
        "print(f\"  - Plots dir: {args.plots_dir}\")\n",
        "print(f\"  - Test split: {args.test_split}\")\n",
        "print(f\"  - Seed: {args.seed}\")\n",
        "print(f\"  - Epochs: {args.epochs}\")\n",
        "print(f\"  - Batch size: {args.batch_size}\")\n",
        "print(f\"  - Learning rate: {args.lr}\")\n",
        "print(f\"  - Early stopping patience: {args.es_patience}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"üöÄ CONFRONTO MODELLI GENERALIZZATI VS PERSONALIZZATI\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Setup environment\n",
        "setup_environment(args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Identifica pazienti estremi\n",
        "best_patient, worst_patient = identify_extreme_patients(args.gru_results_file)\n",
        "target_patients = [best_patient, worst_patient]\n",
        "\n",
        "print(f\"Target patients: {target_patients}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Carica dati originali\n",
        "all_data, X_cols, y_cols = load_original_data()\n",
        "\n",
        "print(f\"Features: {len(X_cols)} columns\")\n",
        "print(f\"Target: {y_cols}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Raccoglitore per tutte le metriche\n",
        "all_metrics = []\n",
        "\n",
        "# Processa ogni paziente target\n",
        "for patient_id in target_patients:\n",
        "    print(f\"\\n\" + \"=\" * 50)\n",
        "    print(f\"PROCESSING PAZIENTE {patient_id}\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Estrai dati del paziente\n",
        "    patient_data = all_data[all_data[\"Patient_ID\"] == patient_id].copy()\n",
        "    print(f\"Dati totali paziente {patient_id}: {len(patient_data)} campioni\")\n",
        "\n",
        "    # Crea split temporali per addestramento modelli personalizzati\n",
        "    train_data, test_data = create_patient_splits(\n",
        "        patient_data, args.test_split, patient_id\n",
        "    )\n",
        "\n",
        "    # Addestra modelli personalizzati\n",
        "    xgb_personalized = train_personalized_xgb(\n",
        "        train_data, X_cols, y_cols, patient_id, args\n",
        "    )\n",
        "    gru_personalized = train_personalized_gru(\n",
        "        train_data, test_data, X_cols, y_cols, patient_id, args\n",
        "    )\n",
        "\n",
        "    # Valuta modelli personalizzati\n",
        "    personalized_results = evaluate_personalized_models(\n",
        "        patient_id,\n",
        "        test_data,\n",
        "        X_cols,\n",
        "        y_cols,\n",
        "        xgb_personalized,\n",
        "        gru_personalized,\n",
        "        args,\n",
        "    )\n",
        "\n",
        "    # Carica risultati modelli generalizzati\n",
        "    generalized_results = load_generalized_results(\n",
        "        patient_id, args.xgb_results_file, args.gru_results_file\n",
        "    )\n",
        "\n",
        "    # Calcola metriche comparative\n",
        "    patient_metrics = calculate_comparison_metrics(\n",
        "        patient_id, personalized_results, generalized_results, args\n",
        "    )\n",
        "\n",
        "    if patient_metrics is not None:\n",
        "        all_metrics.append(patient_metrics)\n",
        "\n",
        "    print(f\"‚úì Completato processamento paziente {patient_id}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Combina tutte le metriche\n",
        "if all_metrics:\n",
        "    all_metrics_df = pd.concat(all_metrics, ignore_index=True)\n",
        "\n",
        "    # Crea riassunto finale\n",
        "    summary_df = create_comparison_summary(all_metrics_df, args)\n",
        "\n",
        "    print(f\"\\n‚úÖ Confronto completato! Risultati salvati in: {args.output_dir}\")\n",
        "\n",
        "    results = {\n",
        "        \"metrics\": all_metrics_df,\n",
        "        \"summary\": summary_df,\n",
        "        \"target_patients\": target_patients,\n",
        "    }\n",
        "else:\n",
        "    print(\"\\n‚ùå Nessun risultato generato\")\n",
        "    results = None"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
